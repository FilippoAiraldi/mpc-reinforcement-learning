from collections import deque
from typing import (
    Any,
    Deque,
    Dict,
    Iterable,
    List,
    Optional,
    SupportsFloat,
    Tuple,
    TypeVar,
)

from gymnasium import Env, Wrapper

ObsType = TypeVar("ObsType")
ActType = TypeVar("ActType")


def compact_dicts_into_one(
    dicts: Iterable[Dict[str, Any]], fill_value: Any = None
) -> Dict[str, List[Any]]:
    """Compacts an iterable of dictionaries into a single dict with lists of entries. If
    an entry is missing for any given dict, `fill_value` is used in place.

    Parameters
    ----------
    dicts : iterable of dicts[str, any]
        Dictionaries to be compacted into a single one.
    fill_value : any, optional
        The value to be used to fill in missing values.

    Returns
    -------
    Dict[str, list of any | fill_value]
        A unique dictionary made from all the passed dicts.
    """
    out: Dict[str, List[Any]] = {}
    for i, dict in enumerate(dicts):
        for k, v in dict.items():
            if k in out:
                out[k].append(v)
            else:
                out[k] = [fill_value] * i + [v]
        for k in out.keys() - dict.keys():
            out[k].append(fill_value)
    return out


class MonitorInfos(Wrapper[ObsType, ActType]):
    """This wrapper keeps track of the infos that are generated by the env when `reset`
    and `step` are called."""

    def __init__(
        self, env: Env[ObsType, ActType], deque_size: Optional[int] = None
    ) -> None:
        """This wrapper will keep track of the reset/step information dicts.

        Parameters
        ----------
        env : Env[ObsType, ActType]
            The environment to apply the wrapper to.
        deque_size : int, optional
            The maximum number of episodes to hold as historical data in the internal
            deques. By default, `None`, i.e., unlimited.
        """
        super().__init__(env)
        # long-term storages
        self.reset_infos: Deque[Dict[str, Any]] = deque(maxlen=deque_size)
        self.step_infos: Deque[Dict[str, List[Any]]] = deque(maxlen=deque_size)
        # current-episode-storages
        self.ep_step_infos: List[Dict[str, Any]] = []

    def reset(
        self, *, seed: Optional[int] = None, options: Optional[Dict[str, Any]] = None
    ) -> Tuple[ObsType, Dict[str, Any]]:
        """Resets the environment and resets the current data accumulators."""
        observation, info = super().reset(seed=seed, options=options)
        self.ep_step_infos.clear()
        self.reset_infos.append(info)
        return observation, info

    def step(
        self, action: ActType
    ) -> Tuple[ObsType, SupportsFloat, bool, bool, Dict[str, Any]]:
        """Steps through the environment, accumulating the episode data."""
        obs, reward, terminated, truncated, info = super().step(action)

        # accumulate data
        self.ep_step_infos.append(info)

        # if episode is done, save the current data to history
        if terminated or truncated:
            self.step_infos.append(compact_dicts_into_one(self.ep_step_infos))
            self.ep_step_infos.clear()
        return obs, reward, terminated, truncated, info
